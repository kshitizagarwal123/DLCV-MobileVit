# Step 1: Dataset Preparation
import tensorflow_datasets as tfds

# Load dataset (example: CIFAR-10)
dataset_name = "cifar10"
(train_ds, test_ds), ds_info = tfds.load(
    name=dataset_name,
    split=["train", "test"],
    shuffle_files=True,
    as_supervised=True,
    with_info=True
)

# Normalize images to [0, 1] range
def normalize_img(image, label):
    return tf.cast(image, tf.float32) / 255.0, label

# Apply normalization
train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)
test_ds = test_ds.map(normalize_img, num_parallel_calls=tf.data.experimental.AUTOTUNE)

# Shuffle and batch the datasets
train_ds = train_ds.shuffle(1024).batch(64).prefetch(tf.data.experimental.AUTOTUNE)
test_ds = test_ds.batch(64).prefetch(tf.data.experimental.AUTOTUNE)

# Step 2: Model Training and Evaluation
# Compile and train the MobileViT model
mobilevit_xxs.compile(
    optimizer=keras.optimizers.Adam(),
    loss=keras.losses.SparseCategoricalCrossentropy(),
    metrics=["accuracy"],
)
mobilevit_history = mobilevit_xxs.fit(train_ds, epochs=10, validation_data=test_ds)

# Compile and train the modified MobileViT model
modified_mobilevit_xxs.compile(
    optimizer=keras.optimizers.Adam(),
    loss=keras.losses.SparseCategoricalCrossentropy(),
    metrics=["accuracy"],
)
modified_mobilevit_history = modified_mobilevit_xxs.fit(train_ds, epochs=10, validation_data=test_ds)

# Evaluate the models
mobilevit_test_loss, mobilevit_test_acc = mobilevit_xxs.evaluate(test_ds)
modified_mobilevit_test_loss, modified_mobilevit_test_acc = modified_mobilevit_xxs.evaluate(test_ds)

print("MobileViT Model:")
print("Test Loss:", mobilevit_test_loss)
print("Test Accuracy:", mobilevit_test_acc)
print("\nModified MobileViT Model:")
print("Test Loss:", modified_mobilevit_test_loss)
print("Test Accuracy:", modified_mobilevit_test_acc)
